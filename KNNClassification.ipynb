{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Classification\n",
    "# K-nearest neighbors classifier (KNN) is a simple and powerful classification learner.\n",
    "# KNN has three basic parts:\n",
    "# 1) yi: The class of an observation (what we are trying to predict in the test data).\n",
    "# 2) Xi: The predictors/Input Variables/attributes of an observation.\n",
    "# 3) K: A positive number specified by the researcher. K denotes the number of neighbors\n",
    "# closest to a particular observation that define its “neighborhood”. For example, K=2 means\n",
    "# that each observation’s has a neighorhood comprising of the two other observations closest\n",
    "# to it.\n",
    "# Imagine we have an observation where we know its independent variables xtest but do not \n",
    "# know its class ytest. The KNN learner finds the K other observations that are closest to \n",
    "# xtest and uses their known classes to assign a class to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Preliminaries__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_1</th>\n",
       "      <th>test_2</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6974</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.4538</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2231</td>\n",
       "      <td>0.4615</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4436</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6308</td>\n",
       "      <td>0.5346</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>loss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_1  test_2 outcome\n",
       "0  0.3051  0.5846     win\n",
       "1  0.4949  0.2654     win\n",
       "2  0.6974  0.2615     win\n",
       "3  0.3769  0.4538     win\n",
       "4  0.2231  0.4615     win\n",
       "5  0.3410  0.8308    loss\n",
       "6  0.4436  0.4962    loss\n",
       "7  0.5897  0.3269    loss\n",
       "8  0.6308  0.5346    loss\n",
       "9  0.5000  0.6731    loss"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataset\n",
    "# Here we create three variables, test_1 and test_2 are our\n",
    "# independent variables, ‘outcome’ is our dependent variable.\n",
    "# We will use this data to train our learner.\n",
    "\n",
    "training_data = pd.DataFrame()\n",
    "\n",
    "training_data['test_1'] = [0.3051,0.4949,0.6974,0.3769,0.2231,0.341,0.4436,0.5897,0.6308,0.5]\n",
    "training_data['test_2'] = [0.5846,0.2654,0.2615,0.4538,0.4615,0.8308,0.4962,0.3269,0.5346,0.6731]\n",
    "training_data['outcome'] = ['win','win','win','win','win','loss','loss','loss','loss','loss']\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnab\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x21dc6f9d160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 415.375x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "# This is not necessary, but because we only have three\n",
    "# variables, we can plot the training dataset. The X and Y\n",
    "# axes are the independent variables, while the colors of\n",
    "# the points are their classes.\n",
    "\n",
    "seaborn.lmplot('test_1', 'test_2', data=training_data, fit_reg=False, hue=\"outcome\", scatter_kws={\"marker\": \"D\",\"s\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [[0.3051 0.5846]\n",
      " [0.4949 0.2654]\n",
      " [0.6974 0.2615]\n",
      " [0.3769 0.4538]\n",
      " [0.2231 0.4615]\n",
      " [0.341  0.8308]\n",
      " [0.4436 0.4962]\n",
      " [0.5897 0.3269]\n",
      " [0.6308 0.5346]\n",
      " [0.5    0.6731]] , Shape: (10, 2)\n",
      "y:  ['win' 'win' 'win' 'win' 'win' 'loss' 'loss' 'loss' 'loss' 'loss'] , Shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "# Convert Data Into np.arrays\n",
    "# The scikit-learn library requires the data be formatted\n",
    "# as a numpy array. Here are doing that reformatting.\n",
    "\n",
    "X = training_data[['test_1', 'test_2']].to_numpy()\n",
    "y = np.array(training_data['outcome'])\n",
    "print (\"X: \",X, \", Shape:\", X.shape)\n",
    "print (\"y: \",y, \", Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train The Learner\n",
    "# We shall train a KNN learner using the\n",
    "# parameters that an observation’s neighborhood is its three\n",
    "# closest neighors. weights = 'uniform' can be thought of as \n",
    "# the voting system used. For example, uniform means that all\n",
    "# neighbors get an equally weighted “vote” about an \n",
    "# observation’s class while weights = 'distance' would tell \n",
    "# the learner to weigh each observation’s “vote” by its\n",
    "# distance from the observation we are classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_model:  KNeighborsClassifier(n_neighbors=3)\n"
     ]
    }
   ],
   "source": [
    "clf = neighbors.KNeighborsClassifier(3, weights = 'uniform')\n",
    "trained_model = clf.fit(X, y)\n",
    "print (\"trained_model: \",trained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View The Model’s Score\n",
    "# How good is our trained model compared to our training \n",
    "# data?\n",
    "trained_model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our model is 80% accurate!\n",
    "# Apply The Learner To A New Data Point\n",
    "# Now that we have trained our model, we can predict the \n",
    "# class any new observation, ytest. Let us do that now!\n",
    "\n",
    "# Create a new observation with the value of the first\n",
    "# independent variable, 'test_1', as .4 \n",
    "# and the second independent variable, 'test_2', as .6 \n",
    "x_test = np.array([[.4,.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['loss'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the learner to the new, unclassified observation.\n",
    "trained_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 0.33333333]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even look at the probabilities the learner assigned \n",
    "# to each class:\n",
    "trained_model.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to this result, the model predicted that the \n",
    "# observation was loss with a ~67% probability and win with \n",
    "# a ~33% probability. Because the observation had a greater\n",
    "# probability of being loss, it predicted that class for the\n",
    "# observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# The choice of K has major affects on the classifer created.\n",
    "# The greater the K, more linear (high bias and low variance)\n",
    "# the decision boundary.\n",
    "# There are a variety of ways to measure distance, two \n",
    "# popular being simple euclidean distance and \n",
    "# cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
